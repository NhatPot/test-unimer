# BÃO CÃO Ká»¸ THUáº¬T: TINH CHá»ˆNH MÃ” HÃŒNH QWEN2.5-VL-3B CHO NHáº¬N Dáº NG BIá»‚U THá»¨C TOÃN Há»ŒC VIáº¾T TAY

> **Dá»±a trÃªn Uni-MuMER**: [NeurIPS 2025 Spotlight ğŸ”¥] Official implementation  
> **Repository gá»‘c**: https://github.com/BFlameSwift/Uni-MuMER  
> **Paper**: [arXiv:2505.23566](https://arxiv.org/abs/2505.23566)  
> **HuggingFace**: [Uni-MuMER-Data](https://huggingface.co/datasets/phxember/Uni-MuMER-Data)

## 1. Tá»”NG QUAN

### 1.0. Giá»›i thiá»‡u vá» Uni-MuMER

**Uni-MuMER** (Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition) lÃ  má»™t phÆ°Æ¡ng phÃ¡p fine-tuning toÃ n diá»‡n mÃ´ hÃ¬nh Qwen2.5-VL-3B cho tÃ¡c vá»¥ nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c viáº¿t tay (HMER) mÃ  khÃ´ng thay Ä‘á»•i kiáº¿n trÃºc cá»§a nÃ³. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c cháº¥p nháº­n táº¡i **NeurIPS 2025 vá»›i danh hiá»‡u Spotlight** (688/21575 submissions).

**ÄÃ³ng gÃ³p chÃ­nh:**
- TÃ­ch há»£p ba tÃ¡c vá»¥ dá»±a trÃªn dá»¯ liá»‡u: Tree-Aware Chain-of-Thought (Tree-CoT), Error-Driven Learning (EDL), vÃ  Symbol Counting (SC)
- Sá»­ dá»¥ng QLoRA + 4-bit quantization Ä‘á»ƒ giáº£m tÃ i nguyÃªn tÃ­nh toÃ¡n
- Äáº¡t hiá»‡u suáº¥t state-of-the-art, vÆ°á»£t SSAN 16.31% vÃ  Gemini2.5-flash 24.42% trong thiáº¿t láº­p zero-shot

**Repository chÃ­nh thá»©c:** [https://github.com/BFlameSwift/Uni-MuMER](https://github.com/BFlameSwift/Uni-MuMER)

### 1.0.1. So sÃ¡nh vá»›i Implementation gá»‘c

BÃ¡o cÃ¡o nÃ y phÃ¢n tÃ­ch cÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng trong **Uni-MuMER gá»‘c** tá»« repository chÃ­nh thá»©c. Dá»± Ã¡n nÃ y lÃ  implementation cá»§a Uni-MuMER vá»›i cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:

| KhÃ­a cáº¡nh | Uni-MuMER gá»‘c (GitHub) | Implementation nÃ y |
|-----------|------------------------|-------------------|
| **Kiáº¿n trÃºc** | Qwen2.5-VL-3B + QLoRA | Giá»‘ng há»‡t (theo repository gá»‘c) |
| **Ká»¹ thuáº­t** | QLoRA, NF4, Multi-task Learning | Giá»‘ng há»‡t |
| **Datasets** | Uni-MuMER-Data tá»« HuggingFace | Sá»­ dá»¥ng cÃ¹ng datasets |
| **Training** | LLaMA-Factory | Sá»­ dá»¥ng LLaMA-Factory |
| **Inference** | vLLM vá»›i 4-bit quantization | Sá»­ dá»¥ng vLLM vá»›i 4-bit |
| **Káº¿t quáº£** | SOTA (vÆ°á»£t SSAN 16.31%) | Reproduce káº¿t quáº£ tá»« paper |

**Káº¿t luáº­n**: Implementation nÃ y tuÃ¢n thá»§ hoÃ n toÃ n phÆ°Æ¡ng phÃ¡p vÃ  cáº¥u hÃ¬nh tá»« repository chÃ­nh thá»©c cá»§a Uni-MuMER. BÃ¡o cÃ¡o nÃ y phÃ¢n tÃ­ch chi tiáº¿t cÃ¡c ká»¹ thuáº­t Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong Uni-MuMER gá»‘c.

### 1.1. MÃ´ hÃ¬nh gá»‘c: Qwen2.5-VL-3B-Instruct

**ThÃ´ng tin cÆ¡ báº£n:**
- **Kiáº¿n trÃºc**: Vision-Language Model (VLM) Ä‘a phÆ°Æ¡ng tiá»‡n
- **KÃ­ch thÆ°á»›c**: 3 tá»· tham sá»‘ (3B)
- **Chá»©c nÄƒng**: Xá»­ lÃ½ vÃ  hiá»ƒu cáº£ hÃ¬nh áº£nh vÃ  vÄƒn báº£n
- **Äá»™ chÃ­nh xÃ¡c**: Full precision (FP32/FP16)
- **VRAM yÃªu cáº§u**: ~60-80GB cho training, ~6GB cho inference

**Äáº·c Ä‘iá»ƒm kiáº¿n trÃºc:**
- Vision Encoder: Xá»­ lÃ½ hÃ¬nh áº£nh Ä‘áº§u vÃ o
- Multi-modal Projector: Káº¿t ná»‘i vision vÃ  language
- Language Model: Xá»­ lÃ½ vÃ  sinh vÄƒn báº£n
- Táº¥t cáº£ cÃ¡c thÃ nh pháº§n Ä‘á»u Ä‘Æ°á»£c trainable trong fine-tuning truyá»n thá»‘ng

### 1.2. Váº¥n Ä‘á» cá»§a mÃ´ hÃ¬nh gá»‘c

1. **YÃªu cáº§u tÃ i nguyÃªn cao**: Cáº§n GPU cÃ³ VRAM lá»›n (â‰¥80GB) Ä‘á»ƒ fine-tuning
2. **Thá»i gian training dÃ i**: Do pháº£i cáº­p nháº­t toÃ n bá»™ tham sá»‘
3. **KhÃ³ triá»ƒn khai**: Model size lá»›n (~3GB) gÃ¢y khÃ³ khÄƒn cho deployment
4. **Chi phÃ­ tÃ­nh toÃ¡n cao**: Tá»‘n nhiá»u nÄƒng lÆ°á»£ng vÃ  thá»i gian

---

## 2. PHÆ¯Æ NG PHÃP Äá»€ XUáº¤T â€“ MÃ” HÃŒNH UNI-MUMER

### 2.1. Äá»™ng cÆ¡ phÃ¡t triá»ƒn tá»« cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c

Trong quÃ¡ trÃ¬nh nghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c viáº¿t tay (HMER), chÃºng ta nháº­n tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh chuyÃªn biá»‡t nhÆ° TAMER, CoMER hay cÃ¡c mÃ´ hÃ¬nh end-to-end truyá»n thá»‘ng máº·c dÃ¹ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t cao nhÆ°ng váº«n tá»“n táº¡i nhá»¯ng háº¡n cháº¿ nháº¥t Ä‘á»‹nh. Cá»¥ thá»ƒ, cÃ¡c mÃ´ hÃ¬nh nÃ y thÆ°á»ng yÃªu cáº§u tÃ i nguyÃªn tÃ­nh toÃ¡n lá»›n, khÃ³ triá»ƒn khai trÃªn pháº§n cá»©ng háº¡n cháº¿, vÃ  chÆ°a táº­n dá»¥ng Ä‘Æ°á»£c triá»‡t Ä‘á»ƒ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh Vision-Language Model (VLM) hiá»‡n Ä‘áº¡i Ä‘Ã£ Ä‘Æ°á»£c pre-train trÃªn dá»¯ liá»‡u Ä‘a dáº¡ng.

**Háº¡n cháº¿ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c:**

1. **YÃªu cáº§u tÃ i nguyÃªn cao**: CÃ¡c mÃ´ hÃ¬nh nhÆ° TAMER, CoMER thÆ°á»ng yÃªu cáº§u GPU cÃ³ VRAM lá»›n (â‰¥80GB) Ä‘á»ƒ fine-tuning toÃ n bá»™ tham sá»‘, gÃ¢y khÃ³ khÄƒn cho viá»‡c nghiÃªn cá»©u vÃ  triá»ƒn khai trong Ä‘iá»u kiá»‡n tÃ i nguyÃªn háº¡n cháº¿.

2. **Thiáº¿u kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a**: CÃ¡c mÃ´ hÃ¬nh chuyÃªn biá»‡t Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng cho HMER thÆ°á»ng kÃ©m hiá»‡u quáº£ khi Ã¡p dá»¥ng sang cÃ¡c tÃ¡c vá»¥ thá»‹ giÃ¡c khÃ¡c, thiáº¿u tÃ­nh linh hoáº¡t vÃ  kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng.

3. **ChÆ°a táº­n dá»¥ng kiáº¿n thá»©c pre-trained**: CÃ¡c mÃ´ hÃ¬nh tá»« Ä‘áº§u (from scratch) khÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c kiáº¿n thá»©c Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« cÃ¡c mÃ´ hÃ¬nh VLM lá»›n nhÆ° Qwen2.5-VL, GPT-4V, hay Gemini, vá»‘n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hÃ ng tá»· dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng tiá»‡n.

4. **Thiáº¿u cÆ¡ cháº¿ há»c tá»« lá»—i**: CÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng khÃ´ng cÃ³ cÆ¡ cháº¿ rÃµ rÃ ng Ä‘á»ƒ há»c tá»« cÃ¡c lá»—i phá»• biáº¿n, dáº«n Ä‘áº¿n viá»‡c láº·p láº¡i cÃ¡c lá»—i tÆ°Æ¡ng tá»± trong quÃ¡ trÃ¬nh nháº­n dáº¡ng.

**LÃ½ do chuyá»ƒn sang Uni-MuMER:**

Uni-MuMER Ä‘Æ°á»£c phÃ¡t triá»ƒn nháº±m kháº¯c phá»¥c nhá»¯ng háº¡n cháº¿ trÃªn báº±ng cÃ¡ch:

1. **Táº­n dá»¥ng mÃ´ hÃ¬nh VLM pre-trained**: Sá»­ dá»¥ng Qwen2.5-VL-3B nhÆ° má»™t base model Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn, táº­n dá»¥ng kiáº¿n thá»©c tá»•ng quÃ¡t vá» thá»‹ giÃ¡c vÃ  ngÃ´n ngá»¯.

2. **Fine-tuning hiá»‡u quáº£ vá»›i QLoRA**: Ãp dá»¥ng ká»¹ thuáº­t QLoRA (Quantized Low-Rank Adaptation) Ä‘á»ƒ giáº£m Ä‘Ã¡ng ká»ƒ yÃªu cáº§u tÃ i nguyÃªn mÃ  váº«n giá»¯ Ä‘Æ°á»£c hiá»‡u suáº¥t cao.

3. **Multi-task learning thá»‘ng nháº¥t**: TÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£ (Tree-CoT, EDL, SC) trong má»™t quÃ¡ trÃ¬nh training thá»‘ng nháº¥t, cho phÃ©p model há»c Ä‘Æ°á»£c nhiá»u khÃ­a cáº¡nh cá»§a bÃ i toÃ¡n HMER Ä‘á»“ng thá»i.

4. **HÆ°á»›ng tiáº¿p cáº­n má»›i**: Tá»« mÃ´ hÃ¬nh chuyÃªn biá»‡t â†’ mÃ´ hÃ¬nh tá»•ng quÃ¡t Ä‘Æ°á»£c fine-tuning, tá»« full fine-tuning â†’ parameter-efficient fine-tuning, tá»« single-task â†’ multi-task learning.

### 2.2. Tá»•ng quan vá» PhÆ°Æ¡ng phÃ¡p Uni-MuMER

**Uni-MuMER** (Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition) lÃ  má»™t phÆ°Æ¡ng phÃ¡p fine-tuning thá»‘ng nháº¥t, tÃ­ch há»£p nhiá»u tÃ¡c vá»¥ Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c viáº¿t tay. PhÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng thay Ä‘á»•i kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh Qwen2.5-VL-3B gá»‘c mÃ  chá»‰ fine-tuning thÃ´ng qua QLoRA Ä‘á»ƒ tÃ­ch há»£p kiáº¿n thá»©c chuyÃªn ngÃ nh vÃ o framework tá»•ng quÃ¡t.

**NguyÃªn táº¯c thiáº¿t káº¿:**

1. **KhÃ´ng thay Ä‘á»•i kiáº¿n trÃºc**: Giá»¯ nguyÃªn kiáº¿n trÃºc cá»§a Qwen2.5-VL-3B, Ä‘áº£m báº£o tÃ­nh tÆ°Æ¡ng thÃ­ch vÃ  dá»… triá»ƒn khai.

2. **Fine-tuning hiá»‡u quáº£**: Sá»­ dá»¥ng QLoRA Ä‘á»ƒ giáº£m tÃ i nguyÃªn tÃ­nh toÃ¡n xuá»‘ng 50-70% so vá»›i full fine-tuning, cho phÃ©p training trÃªn GPU consumer-grade.

3. **Multi-task learning**: TÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£ (Tree-Aware Chain-of-Thought, Error-Driven Learning, Symbol Counting) Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t toÃ n diá»‡n.

4. **Data-driven approach**: CÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c thiáº¿t káº¿ dá»±a trÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u thá»±c táº¿, Ä‘áº£m báº£o tÃ­nh thá»±c tiá»…n vÃ  hiá»‡u quáº£.

### 2.3. Kiáº¿n trÃºc Tá»•ng thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: HÃ¬nh áº£nh biá»ƒu thá»©c toÃ¡n há»c        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vision Encoder (Qwen2.5-VL-3B)                  â”‚
â”‚         [Frozen, 4-bit Quantized vá»›i QLoRA]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Multi-modal Projector (Qwen2.5-VL-3B)                â”‚
â”‚         [Frozen, 4-bit Quantized vá»›i QLoRA]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Language Model (Qwen2.5-VL-3B)                       â”‚
â”‚         [Frozen, 4-bit Quantized vá»›i QLoRA]                  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         LoRA Adapters (Trainable, FP16)            â”‚    â”‚
â”‚  â”‚  - LoRA cho táº¥t cáº£ linear layers                   â”‚    â”‚
â”‚  â”‚  - Rank: 64, Alpha: 16                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OUTPUT: LaTeX/Text biá»ƒu thá»©c toÃ¡n há»c           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Äáº·c Ä‘iá»ƒm kiáº¿n trÃºc:**
- **Base Model**: Qwen2.5-VL-3B Ä‘Æ°á»£c quantize xuá»‘ng 4-bit vÃ  Ä‘Ã³ng bÄƒng
- **LoRA Adapters**: Chá»‰ train cÃ¡c adapters nhá» (rank 64) á»Ÿ full precision
- **Multi-task Learning**: CÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c há»c Ä‘á»“ng thá»i thÃ´ng qua dá»¯ liá»‡u Ä‘a dáº¡ng

### 2.4. Quy trÃ¬nh xá»­ lÃ½ end-to-end

Uni-MuMER hoáº¡t Ä‘á»™ng theo má»™t quy trÃ¬nh end-to-end, chuyá»ƒn Ä‘á»•i trá»±c tiáº¿p tá»« hÃ¬nh áº£nh biá»ƒu thá»©c toÃ¡n há»c viáº¿t tay sang chuá»—i LaTeX. Quy trÃ¬nh nÃ y bao gá»“m cÃ¡c giai Ä‘oáº¡n chÃ­nh sau:

**Giai Ä‘oáº¡n 1: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng thá»‹ giÃ¡c**
- HÃ¬nh áº£nh Ä‘áº§u vÃ o Ä‘Æ°á»£c Ä‘Æ°a vÃ o Vision Encoder cá»§a Qwen2.5-VL-3B
- Vision Encoder sá»­ dá»¥ng kiáº¿n trÃºc transformer-based Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng thá»‹ giÃ¡c Ä‘a tá»· lá»‡
- CÃ¡c Ä‘áº·c trÆ°ng nÃ y Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh má»™t dÃ£y cÃ¡c visual tokens

**Giai Ä‘oáº¡n 2: Káº¿t ná»‘i Ä‘a phÆ°Æ¡ng tiá»‡n**
- Multi-modal Projector káº¿t ná»‘i khÃ´ng gian Ä‘áº·c trÆ°ng thá»‹ giÃ¡c vá»›i khÃ´ng gian ngÃ´n ngá»¯
- QuÃ¡ trÃ¬nh nÃ y cho phÃ©p model hiá»ƒu Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a thÃ´ng tin thá»‹ giÃ¡c vÃ  ngá»¯ nghÄ©a

**Giai Ä‘oáº¡n 3: Xá»­ lÃ½ ngÃ´n ngá»¯ vÃ  sinh vÄƒn báº£n**
- Language Model nháº­n cÃ¡c visual tokens Ä‘Ã£ Ä‘Æ°á»£c project vÃ  xá»­ lÃ½ chÃºng
- LoRA Adapters Ä‘Æ°á»£c Ã¡p dá»¥ng táº¡i cÃ¡c lá»›p linear trong Language Model Ä‘á»ƒ há»c cÃ¡c pattern Ä‘áº·c thÃ¹ cho HMER
- Model sinh ra chuá»—i LaTeX tá»«ng token má»™t, sá»­ dá»¥ng cÆ¡ cháº¿ attention Ä‘á»ƒ táº­p trung vÃ o cÃ¡c vÃ¹ng quan trá»ng

**Giai Ä‘oáº¡n 4: Ãp dá»¥ng Multi-task Learning**
- Trong quÃ¡ trÃ¬nh training, model Ä‘á»“ng thá»i há»c ba tÃ¡c vá»¥:
  - **Tree-CoT**: Há»c cÃ¡ch phÃ¢n tÃ­ch cáº¥u trÃºc cÃ¢y vÃ  suy luáº­n tá»«ng bÆ°á»›c
  - **EDL**: Há»c cÃ¡ch phÃ¡t hiá»‡n vÃ  sá»­a lá»—i
  - **SC**: Há»c cÃ¡ch Ä‘áº¿m vÃ  kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n

### 2.5. Ba TÃ¡c vá»¥ ChÃ­nh trong Uni-MuMER

Uni-MuMER tÃ­ch há»£p **ba tÃ¡c vá»¥ dá»±a trÃªn dá»¯ liá»‡u** Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t nháº­n dáº¡ng:

#### 2.5.1. Tree-Aware Chain-of-Thought (Tree-CoT)

**Má»¥c Ä‘Ã­ch vÃ  Ä‘á»™ng cÆ¡:**

Tree-Aware Chain-of-Thought (Tree-CoT) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n nháº¥t trong nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c: viá»‡c hiá»ƒu vÃ  biá»ƒu diá»…n Ä‘Ãºng cáº¥u trÃºc phÃ¢n cáº¥p cá»§a biá»ƒu thá»©c. KhÃ¡c vá»›i vÄƒn báº£n tuyáº¿n tÃ­nh, biá»ƒu thá»©c toÃ¡n há»c cÃ³ cáº¥u trÃºc hai chiá»u phá»©c táº¡p, trong Ä‘Ã³ vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i cá»§a cÃ¡c kÃ½ hiá»‡u (trÃªn, dÆ°á»›i, chá»‰ sá»‘, mÅ©) quyáº¿t Ä‘á»‹nh Ã½ nghÄ©a cá»§a biá»ƒu thá»©c.

**CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**

1. **Biá»ƒu diá»…n cáº¥u trÃºc cÃ¢y**: 
   - Biá»ƒu thá»©c toÃ¡n há»c Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng cÃ¢y nhá»‹ phÃ¢n hoáº·c cÃ¢y Ä‘a phÃ¢n (tree structure)
   - Má»—i node trong cÃ¢y Ä‘áº¡i diá»‡n cho má»™t toÃ¡n tá»­ hoáº·c toÃ¡n háº¡ng
   - Edges biá»ƒu thá»‹ quan há»‡ giá»¯a cÃ¡c thÃ nh pháº§n (quan há»‡ cha-con, quan há»‡ anh em)
   - Cáº¥u trÃºc cÃ¢y nÃ y pháº£n Ã¡nh thá»© tá»± Æ°u tiÃªn cá»§a cÃ¡c phÃ©p toÃ¡n (operator precedence) vÃ  cáº¥u trÃºc ngá»¯ phÃ¡p cá»§a biá»ƒu thá»©c
   
2. **Chain-of-Thought reasoning**: 
   Model há»c cÃ¡ch suy luáº­n tá»«ng bÆ°á»›c theo cáº¥u trÃºc cÃ¢y:
   ```
   Input: HÃ¬nh áº£nh biá»ƒu thá»©c toÃ¡n há»c
   â†“
   BÆ°á»›c 1: Nháº­n dáº¡ng cÃ¡c kÃ½ hiá»‡u cÆ¡ báº£n (symbols, numbers, operators)
   â†“
   BÆ°á»›c 2: PhÃ¢n tÃ­ch vá»‹ trÃ­ khÃ´ng gian vÃ  xÃ¡c Ä‘á»‹nh cáº¥u trÃºc cÃ¢y
          (operator precedence, parent-child relationships)
   â†“
   BÆ°á»›c 3: XÃ¢y dá»±ng biá»ƒu thá»©c LaTeX theo cáº¥u trÃºc cÃ¢y Ä‘Ã£ xÃ¡c Ä‘á»‹nh
          (Ä‘áº£m báº£o Ä‘Ãºng thá»© tá»± tÃ­nh toÃ¡n vÃ  cÃº phÃ¡p)
   â†“
   Output: Chuá»—i LaTeX chÃ­nh xÃ¡c
   ```

3. **Training data vÃ  annotation**: 
   - Dataset `parquet_crohme_train_tree`: Chá»©a thÃ´ng tin cáº¥u trÃºc cÃ¢y Ä‘Æ°á»£c annotate thá»§ cÃ´ng, bao gá»“m cáº£ quan há»‡ khÃ´ng gian giá»¯a cÃ¡c kÃ½ hiá»‡u
   - Dataset `parquet_crohme_train_can`: Canonical form cá»§a biá»ƒu thá»©c vá»›i cáº¥u trÃºc cÃ¢y chuáº©n hÃ³a, giÃºp model há»c Ä‘Æ°á»£c cÃ¡ch biá»ƒu diá»…n nháº¥t quÃ¡n

**VÃ­ dá»¥:**
```
Biá»ƒu thá»©c: (a + b) Ã— c
Cáº¥u trÃºc cÃ¢y:
        Ã—
       / \
      +   c
     / \
    a   b

Chain-of-Thought:
1. Nháº­n dáº¡ng: "(", "a", "+", "b", ")", "Ã—", "c"
2. PhÃ¢n tÃ­ch: PhÃ©p nhÃ¢n cÃ³ precedence cao hÆ¡n, nhÆ°ng cÃ³ dáº¥u ngoáº·c
3. Cáº¥u trÃºc: (a+b) Ä‘Æ°á»£c tÃ­nh trÆ°á»›c, sau Ä‘Ã³ nhÃ¢n vá»›i c
4. Output: \left(a+b\right) \times c
```

**Lá»£i Ã­ch vÃ  hiá»‡u quáº£:**

- **Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cho biá»ƒu thá»©c phá»©c táº¡p**: Äáº·c biá»‡t hiá»‡u quáº£ vá»›i cÃ¡c biá»ƒu thá»©c cÃ³ nhiá»u dáº¥u ngoáº·c, phÃ¢n sá»‘, chá»‰ sá»‘ trÃªn/dÆ°á»›i, vÃ  cÃ¡c cáº¥u trÃºc lá»“ng nhau.

- **Giáº£m lá»—i vá» operator precedence**: Model há»c Ä‘Æ°á»£c thá»© tá»± Æ°u tiÃªn cá»§a cÃ¡c phÃ©p toÃ¡n thÃ´ng qua cáº¥u trÃºc cÃ¢y, giáº£m Ä‘Ã¡ng ká»ƒ cÃ¡c lá»—i vá» thá»© tá»± tÃ­nh toÃ¡n.

- **Hiá»ƒu sÃ¢u vá» cáº¥u trÃºc toÃ¡n há»c**: Thay vÃ¬ chá»‰ nháº­n dáº¡ng tá»«ng kÃ½ hiá»‡u riÃªng láº», model hiá»ƒu Ä‘Æ°á»£c má»‘i quan há»‡ vÃ  cáº¥u trÃºc tá»•ng thá»ƒ cá»§a biá»ƒu thá»©c, dáº«n Ä‘áº¿n káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n.

- **Kháº£ nÄƒng xá»­ lÃ½ biá»ƒu thá»©c dÃ i**: Cáº¥u trÃºc cÃ¢y giÃºp model quáº£n lÃ½ vÃ  xá»­ lÃ½ cÃ¡c biá»ƒu thá»©c dÃ i vÃ  phá»©c táº¡p má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng.

#### 2.5.2. Error-Driven Learning (EDL)

**Má»¥c Ä‘Ã­ch vÃ  Ä‘á»™ng cÆ¡:**

Error-Driven Learning (EDL) Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ giáº£i quyáº¿t má»™t váº¥n Ä‘á» phá»• biáº¿n trong nháº­n dáº¡ng kÃ½ tá»± viáº¿t tay: sá»± nháº§m láº«n giá»¯a cÃ¡c kÃ½ tá»± cÃ³ hÃ¬nh dáº¡ng tÆ°Æ¡ng tá»±. Trong biá»ƒu thá»©c toÃ¡n há»c, viá»‡c nháº§m láº«n giá»¯a cÃ¡c kÃ½ tá»± nhÆ° "0" vÃ  "O", "1" vÃ  "l", hay "Ã—" vÃ  "x" cÃ³ thá»ƒ dáº«n Ä‘áº¿n káº¿t quáº£ hoÃ n toÃ n sai. EDL cho phÃ©p model há»c tá»« cÃ¡c lá»—i phá»• biáº¿n vÃ  tá»± Ä‘á»™ng sá»­a chÃºng.

**CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**

EDL hoáº¡t Ä‘á»™ng theo **hai giai Ä‘oáº¡n tuáº§n tá»±**, mÃ´ phá»ng quÃ¡ trÃ¬nh con ngÆ°á»i phÃ¡t hiá»‡n vÃ  sá»­a lá»—i:

1. **Error Finding (Giai Ä‘oáº¡n phÃ¡t hiá»‡n lá»—i)**:
   - Model Ä‘Æ°á»£c training Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c lá»—i trong quÃ¡ trÃ¬nh nháº­n dáº¡ng
   - Dataset: `parquet_crohme_train_error_find` chá»©a cÃ¡c cáº·p (hÃ¬nh áº£nh, prediction cÃ³ lá»—i, vá»‹ trÃ­ lá»—i)
   - Má»¥c tiÃªu: Há»c cÃ¡c pattern lá»—i phá»• biáº¿n, nháº­n biáº¿t khi nÃ o vÃ  á»Ÿ Ä‘Ã¢u model cÃ³ kháº£ nÄƒng máº¯c lá»—i
   - Model há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n biá»‡t giá»¯a cÃ¡c cáº·p kÃ½ tá»± dá»… nháº§m láº«n

2. **Error Fixing (Giai Ä‘oáº¡n sá»­a lá»—i)**:
   - Model Ä‘Æ°á»£c training Ä‘á»ƒ sá»­a cÃ¡c lá»—i Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t hiá»‡n
   - Dataset: `parquet_crohme_train_error_fix` chá»©a cÃ¡c cáº·p (hÃ¬nh áº£nh, lá»—i Ä‘Ã£ phÃ¡t hiá»‡n, prediction Ä‘Ãºng)
   - Má»¥c tiÃªu: Há»c cÃ¡ch sá»­a lá»—i má»™t cÃ¡ch chÃ­nh xÃ¡c, chuyá»ƒn Ä‘á»•i tá»« prediction sai sang prediction Ä‘Ãºng
   - Model há»c Ä‘Æ°á»£c cÃ¡ch sá»­ dá»¥ng ngá»¯ cáº£nh vÃ  thÃ´ng tin thá»‹ giÃ¡c Ä‘á»ƒ phÃ¢n biá»‡t cÃ¡c kÃ½ tá»± tÆ°Æ¡ng tá»±

**CÃ¡c cáº·p kÃ½ tá»± dá»… nháº§m láº«n:**
- `0` vs `O` (sá»‘ khÃ´ng vs chá»¯ O)
- `1` vs `l` (sá»‘ má»™t vs chá»¯ l)
- `2` vs `z` (sá»‘ hai vs chá»¯ z)
- `5` vs `S` (sá»‘ nÄƒm vs chá»¯ S)
- `6` vs `b` (sá»‘ sÃ¡u vs chá»¯ b)
- `+` vs `t` (dáº¥u cá»™ng vs chá»¯ t)
- `Ã—` vs `x` (dáº¥u nhÃ¢n vs chá»¯ x)
- `Ã·` vs cÃ¡c kÃ½ hiá»‡u khÃ¡c

**Training procedure:**
```
1. Error Finding Task:
   Input: HÃ¬nh áº£nh + Prediction cÃ³ lá»—i
   Output: Vá»‹ trÃ­ vÃ  loáº¡i lá»—i
   
2. Error Fixing Task:
   Input: HÃ¬nh áº£nh + Lá»—i Ä‘Ã£ phÃ¡t hiá»‡n
   Output: Prediction Ä‘Ã£ Ä‘Æ°á»£c sá»­a
```

**VÃ­ dá»¥:**
```
Input image: Biá»ƒu thá»©c "2x + 3"
Model prediction (cÃ³ lá»—i): "2z + 3"  (nháº§m x thÃ nh z)
Error Finding: PhÃ¡t hiá»‡n lá»—i á»Ÿ vá»‹ trÃ­ kÃ½ tá»± thá»© 2
Error Fixing: Sá»­a "z" thÃ nh "x"
Final output: "2x + 3"
```

**Lá»£i Ã­ch vÃ  hiá»‡u quáº£:**

- **Giáº£m Ä‘Ã¡ng ká»ƒ lá»—i nháº§m láº«n**: EDL giÃºp giáº£m Ä‘Ã¡ng ká»ƒ cÃ¡c lá»—i nháº§m láº«n giá»¯a cÃ¡c cáº·p kÃ½ tá»± tÆ°Æ¡ng tá»±, má»™t trong nhá»¯ng nguyÃªn nhÃ¢n chÃ­nh gÃ¢y ra lá»—i trong HMER.

- **Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ**: Báº±ng cÃ¡ch há»c tá»« lá»—i vÃ  tá»± Ä‘á»™ng sá»­a chÃºng, model Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ cao hÆ¡n, Ä‘áº·c biá»‡t trÃªn cÃ¡c biá»ƒu thá»©c cÃ³ nhiá»u kÃ½ tá»± dá»… nháº§m láº«n.

- **Há»c tá»« kinh nghiá»‡m**: Model há»c Ä‘Æ°á»£c tá»« cÃ¡c lá»—i phá»• biáº¿n trong dá»¯ liá»‡u training, tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch con ngÆ°á»i há»c tá»« sai láº§m, dáº«n Ä‘áº¿n kháº£ nÄƒng nháº­n dáº¡ng tá»‘t hÆ¡n.

- **TÄƒng tÃ­nh robust**: Model trá»Ÿ nÃªn robust hÆ¡n vá»›i cÃ¡c biáº¿n thá»ƒ trong cÃ¡ch viáº¿t tay, cÃ³ thá»ƒ xá»­ lÃ½ tá»‘t cÃ¡c trÆ°á»ng há»£p edge cases.

#### 2.5.3. Symbol Counting (SC)

**Má»¥c Ä‘Ã­ch vÃ  Ä‘á»™ng cÆ¡:**

Symbol Counting (SC) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» thiáº¿u hoáº·c thá»«a kÃ½ hiá»‡u trong quÃ¡ trÃ¬nh nháº­n dáº¡ng, Ä‘áº·c biá»‡t vá»›i cÃ¡c biá»ƒu thá»©c dÃ i vÃ  phá»©c táº¡p. Khi model nháº­n dáº¡ng má»™t biá»ƒu thá»©c dÃ i, viá»‡c bá» sÃ³t má»™t vÃ i kÃ½ hiá»‡u hoáº·c thÃªm kÃ½ hiá»‡u khÃ´ng tá»“n táº¡i lÃ  khÃ¡ phá»• biáº¿n. SC giÃºp model tá»± kiá»ƒm tra vÃ  Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n giá»¯a Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra.

**CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**

1. **Symbol Counting Task (Nhiá»‡m vá»¥ Ä‘áº¿m kÃ½ hiá»‡u)**: 
   Model Ä‘Æ°á»£c training Ä‘á»ƒ Ä‘áº¿m vÃ  phÃ¢n loáº¡i sá»‘ lÆ°á»£ng kÃ½ hiá»‡u trong biá»ƒu thá»©c:
   - Äáº¿m sá»‘ toÃ¡n tá»­ (+, -, Ã—, Ã·, =, <, >, â‰¤, â‰¥, ...)
   - Äáº¿m sá»‘ toÃ¡n háº¡ng (sá»‘, biáº¿n, háº±ng sá»‘, ...)
   - Äáº¿m sá»‘ dáº¥u ngoáº·c (má»Ÿ, Ä‘Ã³ng, cÃ¡c loáº¡i ngoáº·c khÃ¡c nhau)
   - Äáº¿m cÃ¡c kÃ½ hiá»‡u Ä‘áº·c biá»‡t (âˆš, âˆ«, âˆ‘, âˆ, ...)

2. **Consistency Check (Kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n)**: 
   Model kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n giá»¯a:
   - Sá»‘ lÆ°á»£ng kÃ½ hiá»‡u Ä‘Æ°á»£c phÃ¡t hiá»‡n trong hÃ¬nh áº£nh Ä‘áº§u vÃ o
   - Sá»‘ lÆ°á»£ng kÃ½ hiá»‡u Ä‘Æ°á»£c sinh ra trong output LaTeX
   - Cáº¥u trÃºc vÃ  Ä‘á»™ phá»©c táº¡p cá»§a biá»ƒu thá»©c
   - Sá»± cÃ¢n báº±ng giá»¯a cÃ¡c loáº¡i kÃ½ hiá»‡u (vÃ­ dá»¥: sá»‘ dáº¥u ngoáº·c má»Ÿ pháº£i báº±ng sá»‘ dáº¥u ngoáº·c Ä‘Ã³ng)

3. **Training vÃ  Self-correction**: 
   Model Ä‘Æ°á»£c training Ä‘á»ƒ:
   - Äáº¿m chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng kÃ½ hiá»‡u tá»« hÃ¬nh áº£nh
   - So sÃ¡nh vá»›i sá»‘ lÆ°á»£ng kÃ½ hiá»‡u trong output
   - PhÃ¡t hiá»‡n khi cÃ³ sá»± khÃ´ng nháº¥t quÃ¡n (thiáº¿u hoáº·c thá»«a kÃ½ hiá»‡u)
   - Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh hoáº·c yÃªu cáº§u nháº­n dáº¡ng láº¡i khi phÃ¡t hiá»‡n lá»—i

**VÃ­ dá»¥:**
```
Input image: Biá»ƒu thá»©c dÃ i vá»›i 15 kÃ½ hiá»‡u
Model prediction: Chá»‰ cÃ³ 12 kÃ½ hiá»‡u (thiáº¿u 3 kÃ½ hiá»‡u)

Symbol Counting:
- Äáº¿m trong image: 15 symbols
- Äáº¿m trong prediction: 12 symbols
- PhÃ¡t hiá»‡n: Thiáº¿u 3 symbols
- Action: YÃªu cáº§u model nháº­n dáº¡ng láº¡i hoáº·c bá»• sung
```

**Lá»£i Ã­ch vÃ  hiá»‡u quáº£:**

- **Giáº£m lá»—i thiáº¿u/thá»«a kÃ½ hiá»‡u**: SC giÃºp giáº£m Ä‘Ã¡ng ká»ƒ cÃ¡c lá»—i thiáº¿u hoáº·c thá»«a kÃ½ hiá»‡u trong biá»ƒu thá»©c dÃ i, má»™t váº¥n Ä‘á» phá»• biáº¿n trong cÃ¡c mÃ´ hÃ¬nh nháº­n dáº¡ng.

- **Cáº£i thiá»‡n tÃ­nh nháº¥t quÃ¡n**: Báº±ng cÃ¡ch kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n giá»¯a Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra, model Ä‘áº£m báº£o ráº±ng táº¥t cáº£ cÃ¡c kÃ½ hiá»‡u trong hÃ¬nh áº£nh Ä‘á»u Ä‘Æ°á»£c nháº­n dáº¡ng vÃ  khÃ´ng cÃ³ kÃ½ hiá»‡u nÃ o Ä‘Æ°á»£c thÃªm vÃ o khÃ´ng Ä‘Ãºng.

- **Äáº·c biá»‡t hiá»‡u quáº£ cho biá»ƒu thá»©c phá»©c táº¡p**: SC Ä‘áº·c biá»‡t há»¯u Ã­ch vá»›i cÃ¡c biá»ƒu thá»©c dÃ i, cÃ³ nhiá»u thÃ nh pháº§n, vÃ  cÃ¡c biá»ƒu thá»©c cÃ³ cáº¥u trÃºc lá»“ng nhau phá»©c táº¡p.

- **Tá»± kiá»ƒm tra vÃ  tá»± sá»­a**: Model cÃ³ kháº£ nÄƒng tá»± kiá»ƒm tra vÃ  tá»± sá»­a lá»—i, tÆ°Æ¡ng tá»± nhÆ° quÃ¡ trÃ¬nh proofreading cá»§a con ngÆ°á»i.

### 2.6. Thiáº¿t káº¿ Multi-Task Learning

Viá»‡c tÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£ vÃ o má»™t quÃ¡ trÃ¬nh training thá»‘ng nháº¥t lÃ  má»™t trong nhá»¯ng Ä‘Ã³ng gÃ³p quan trá»ng cá»§a Uni-MuMER. PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p model há»c Ä‘Æ°á»£c nhiá»u khÃ­a cáº¡nh cá»§a bÃ i toÃ¡n HMER Ä‘á»“ng thá»i, táº­n dá»¥ng Ä‘Æ°á»£c sá»± tÆ°Æ¡ng quan giá»¯a cÃ¡c tÃ¡c vá»¥ Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t tá»•ng thá»ƒ.

#### 2.6.1. CÆ¡ cháº¿ TÃ­ch há»£p

Ba tÃ¡c vá»¥ Ä‘Æ°á»£c tÃ­ch há»£p thÃ´ng qua **multi-task learning** trong má»™t quÃ¡ trÃ¬nh training thá»‘ng nháº¥t:

```
Training Data Mix:
â”œâ”€â”€ Standard HMER (parquet_crohme_train)
â”‚   â””â”€â”€ Nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c cÆ¡ báº£n
â”‚
â”œâ”€â”€ Tree-CoT Tasks
â”‚   â”œâ”€â”€ parquet_crohme_train_tree (cáº¥u trÃºc cÃ¢y)
â”‚   â””â”€â”€ parquet_crohme_train_can (canonical form)
â”‚
â”œâ”€â”€ Error-Driven Learning
â”‚   â”œâ”€â”€ parquet_crohme_train_error_find (tÃ¬m lá»—i)
â”‚   â””â”€â”€ parquet_crohme_train_error_fix (sá»­a lá»—i)
â”‚
â””â”€â”€ Additional Datasets
    â””â”€â”€ parquet_hme100k_train (HME100K dataset)
```

#### 2.6.2. Training Procedure

**Quy trÃ¬nh training thá»‘ng nháº¥t:**

1. **Data Mixing**: Trá»™n táº¥t cáº£ cÃ¡c datasets vá»›i tá»· lá»‡ phÃ¹ há»£p
2. **Unified Training**: Training táº¥t cáº£ cÃ¡c tÃ¡c vá»¥ cÃ¹ng lÃºc
3. **Shared Representation**: Táº¥t cáº£ tÃ¡c vá»¥ chia sáº» cÃ¹ng má»™t base model
4. **Task-specific Learning**: LoRA adapters há»c cÃ¡c pattern riÃªng cho tá»«ng tÃ¡c vá»¥

**Loss Function vÃ  cÆ¡ cháº¿ tá»‘i Æ°u:**

HÃ m loss tá»•ng há»£p Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:

```
L_total = L_HMER + Î±â‚ Ã— L_Tree-CoT + Î±â‚‚ Ã— L_EDL + Î±â‚ƒ Ã— L_SC
```

Trong Ä‘Ã³:
- `L_HMER`: Cross-entropy loss cho tÃ¡c vá»¥ nháº­n dáº¡ng chÃ­nh (tá»« hÃ¬nh áº£nh sang LaTeX)
- `L_Tree-CoT`: Loss cho Tree-CoT reasoning, thÆ°á»ng lÃ  combination loss giá»¯a symbol recognition vÃ  tree structure prediction
- `L_EDL`: Loss cho Error-Driven Learning, bao gá»“m cáº£ error detection loss vÃ  error correction loss
- `L_SC`: Loss cho Symbol Counting, thÆ°á»ng lÃ  L1 hoáº·c L2 loss giá»¯a sá»‘ lÆ°á»£ng kÃ½ hiá»‡u dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿
- `Î±â‚, Î±â‚‚, Î±â‚ƒ`: Trá»ng sá»‘ cho cÃ¡c tÃ¡c vá»¥ phá»¥, Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ cÃ¢n báº±ng giá»¯a cÃ¡c tÃ¡c vá»¥

**CÆ¡ cháº¿ Ä‘iá»u chá»‰nh trá»ng sá»‘:**

Trong quÃ¡ trÃ¬nh training, cÃ¡c trá»ng sá»‘ `Î±â‚, Î±â‚‚, Î±â‚ƒ` cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»™ng dá»±a trÃªn:
- Äá»™ khÃ³ cá»§a tá»«ng tÃ¡c vá»¥ táº¡i má»—i giai Ä‘oáº¡n training
- Tá»· lá»‡ há»™i tá»¥ cá»§a tá»«ng tÃ¡c vá»¥
- Táº§m quan trá»ng tÆ°Æ¡ng Ä‘á»‘i cá»§a tá»«ng tÃ¡c vá»¥ Ä‘á»‘i vá»›i hiá»‡u suáº¥t tá»•ng thá»ƒ

**Gradient flow vÃ  backpropagation:**

Trong quÃ¡ trÃ¬nh backpropagation, gradients tá»« táº¥t cáº£ cÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c tá»•ng há»£p vÃ  cáº­p nháº­t vÃ o LoRA adapters. Äiá»u nÃ y cho phÃ©p:
- CÃ¡c tÃ¡c vá»¥ chia sáº» thÃ´ng tin vÃ  há»c há»i láº«n nhau
- LoRA adapters há»c Ä‘Æ°á»£c cÃ¡c pattern chung vÃ  pattern riÃªng cho tá»«ng tÃ¡c vá»¥
- Tá»‘i Æ°u hÃ³a hiá»‡u quáº£ vá»›i má»™t láº§n forward vÃ  backward pass cho táº¥t cáº£ cÃ¡c tÃ¡c vá»¥

#### 2.6.3. Lá»£i Ã­ch vÃ  hiá»‡u quáº£ cá»§a Multi-Task Learning

1. **Transfer Learning vÃ  Knowledge Sharing**: 
   - Kiáº¿n thá»©c tá»« cÃ¡c tÃ¡c vá»¥ phá»¥ (Tree-CoT, EDL, SC) giÃºp cáº£i thiá»‡n tÃ¡c vá»¥ chÃ­nh (HMER)
   - CÃ¡c tÃ¡c vá»¥ chia sáº» representation learning, cho phÃ©p model há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng chung há»¯u Ã­ch
   - VÃ­ dá»¥: Kiáº¿n thá»©c vá» cáº¥u trÃºc cÃ¢y tá»« Tree-CoT giÃºp model hiá»ƒu rÃµ hÆ¡n vá» cáº¥u trÃºc biá»ƒu thá»©c trong tÃ¡c vá»¥ chÃ­nh

2. **Regularization vÃ  Generalization**: 
   - CÃ¡c tÃ¡c vá»¥ phá»¥ hoáº¡t Ä‘á»™ng nhÆ° má»™t dáº¡ng regularization, ngÄƒn model overfit vÃ o tÃ¡c vá»¥ chÃ­nh
   - Model há»c Ä‘Æ°á»£c cÃ¡c pattern tá»•ng quÃ¡t hÆ¡n, khÃ´ng chá»‰ táº­p trung vÃ o má»™t khÃ­a cáº¡nh cá»¥ thá»ƒ
   - Dáº«n Ä‘áº¿n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n trÃªn dá»¯ liá»‡u test

3. **Robustness vÃ  Error Handling**: 
   - Model trá»Ÿ nÃªn robust hÆ¡n vá»›i cÃ¡c trÆ°á»ng há»£p edge cases nhá» há»c Ä‘Æ°á»£c nhiá»u khÃ­a cáº¡nh cá»§a bÃ i toÃ¡n
   - EDL giÃºp model tá»± phÃ¡t hiá»‡n vÃ  sá»­a lá»—i, SC giÃºp Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n
   - Tree-CoT giÃºp model xá»­ lÃ½ tá»‘t cÃ¡c biá»ƒu thá»©c phá»©c táº¡p

4. **Efficiency vÃ  Scalability**: 
   - Training má»™t láº§n cho nhiá»u tÃ¡c vá»¥ thay vÃ¬ training riÃªng láº», tiáº¿t kiá»‡m thá»i gian vÃ  tÃ i nguyÃªn
   - Chia sáº» base model vÃ  má»™t pháº§n LoRA adapters giá»¯a cÃ¡c tÃ¡c vá»¥, giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cáº§n train
   - Dá»… dÃ ng má»Ÿ rá»™ng thÃªm cÃ¡c tÃ¡c vá»¥ má»›i trong tÆ°Æ¡ng lai

### 2.7. CÆ¡ cháº¿ káº¿t há»£p QLoRA trong Uni-MuMER

QLoRA (Quantized Low-Rank Adaptation) Ä‘Ã³ng vai trÃ² then chá»‘t trong viá»‡c giáº£m yÃªu cáº§u tÃ i nguyÃªn cá»§a Uni-MuMER. Ká»¹ thuáº­t nÃ y cho phÃ©p fine-tuning mÃ´ hÃ¬nh lá»›n vá»›i tÃ i nguyÃªn háº¡n cháº¿ mÃ  váº«n giá»¯ Ä‘Æ°á»£c hiá»‡u suáº¥t cao.

#### 2.7.1. Táº¡i sao sá»­ dá»¥ng QLoRA?

1. **Giáº£m tÃ i nguyÃªn**: Cho phÃ©p training trÃªn GPU consumer-grade
2. **Giá»¯ nguyÃªn kiáº¿n trÃºc**: KhÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc cá»§a Qwen2.5-VL-3B
3. **Hiá»‡u quáº£**: Chá»‰ train má»™t pháº§n nhá» tham sá»‘ nhÆ°ng váº«n Ä‘áº¡t hiá»‡u suáº¥t cao
4. **Linh hoáº¡t**: Dá»… dÃ ng thá»­ nghiá»‡m vá»›i nhiá»u cáº¥u hÃ¬nh khÃ¡c nhau

#### 2.7.2. Cáº¥u hÃ¬nh QLoRA trong Uni-MuMER

```yaml
# Cáº¥u hÃ¬nh tá»« train/Uni-MuMER-train.yaml

# Quantization
quantization_bit: 4              # 4-bit quantization
quantization_type: nf4            # NormalFloat4

# LoRA Configuration
finetuning_type: lora
lora_target: all                  # Ãp dá»¥ng cho táº¥t cáº£ linear layers
lora_rank: 64                     # Rank cá»§a ma tráº­n phÃ¢n tÃ­ch
lora_alpha: 16                    # Scaling factor
lora_dropout: 0.05                # Dropout rate

# Training
per_device_train_batch_size: 2
gradient_accumulation_steps: 64    # Effective batch size = 128
learning_rate: 1.0e-4
bf16: true
```

#### 2.7.3. TÆ°Æ¡ng tÃ¡c giá»¯a QLoRA vÃ  Multi-Task Learning

- **Base Model (4-bit)**: Chá»©a kiáº¿n thá»©c tá»•ng quÃ¡t tá»« Qwen2.5-VL-3B
- **LoRA Adapters**: Há»c cÃ¡c pattern riÃªng cho tá»«ng tÃ¡c vá»¥
- **Shared Learning**: CÃ¡c tÃ¡c vá»¥ chia sáº» má»™t pháº§n adapters, má»™t pháº§n riÃªng biá»‡t

### 2.8. PhÃ¢n tÃ­ch Ä‘á»™ phá»©c táº¡p vÃ  hiá»‡u suáº¥t tÃ­nh toÃ¡n

#### 2.8.1. Äá»™ phá»©c táº¡p tÃ­nh toÃ¡n

**Äá»™ phá»©c táº¡p thá»i gian:**
- **Forward pass**: O(n Ã— dÂ²) vá»›i n lÃ  sá»‘ tokens vÃ  d lÃ  chiá»u cá»§a hidden states. Tuy nhiÃªn, do base model Ä‘Æ°á»£c quantize xuá»‘ng 4-bit, Ä‘á»™ phá»©c táº¡p thá»±c táº¿ giáº£m Ä‘Ã¡ng ká»ƒ.
- **Backward pass**: Chá»‰ tÃ­nh gradient cho LoRA adapters (rank r=64), Ä‘á»™ phá»©c táº¡p giáº£m tá»« O(n Ã— dÂ²) xuá»‘ng O(n Ã— d Ã— r), vá»›i r << d.
- **Tá»•ng Ä‘á»™ phá»©c táº¡p**: O(n Ã— d Ã— r) thay vÃ¬ O(n Ã— dÂ²) nhÆ° full fine-tuning.

**Äá»™ phá»©c táº¡p khÃ´ng gian:**
- **Base model (4-bit)**: ~1.5GB thay vÃ¬ ~6GB (FP16)
- **LoRA adapters**: ~0.1GB (chá»‰ train adapters)
- **Optimizer states**: ~0.2GB (chá»‰ cho adapters) thay vÃ¬ ~12GB
- **Tá»•ng cá»™ng**: ~20-30GB thay vÃ¬ ~60-80GB

#### 2.8.2. Hiá»‡u suáº¥t tÃ­nh toÃ¡n

**Tá»‘c Ä‘á»™ training:**
- Nhanh hÆ¡n 2-3 láº§n so vá»›i full fine-tuning do chá»‰ cáº­p nháº­t má»™t pháº§n nhá» tham sá»‘
- Gradient computation Ä‘Æ¡n giáº£n hÆ¡n nhá» low-rank factorization

**Hiá»‡u suáº¥t inference:**
- CÃ³ thá»ƒ merge LoRA adapters vÃ o base model Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ inference
- Hoáº·c giá»¯ nguyÃªn adapters riÃªng biá»‡t Ä‘á»ƒ linh hoáº¡t hÆ¡n trong viá»‡c chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c tÃ¡c vá»¥

### 2.9. Pipeline Training vÃ  Inference

#### 2.9.1. Training Pipeline

```
1. Load Base Model (Qwen2.5-VL-3B)
   â†“
2. Apply 4-bit Quantization (NF4)
   â†“
3. Initialize LoRA Adapters
   - Target: All linear layers
   - Rank: 64, Alpha: 16
   â†“
4. Load Multi-Task Datasets
   - Standard HMER
   - Tree-CoT variants
   - EDL (error_find, error_fix)
   - HME100K
   â†“
5. Unified Training
   - Mix all datasets
   - Train LoRA adapters only
   - Use gradient accumulation
   â†“
6. Save Checkpoints
   - Only save LoRA adapters (~100MB)
```

#### 2.9.2. Inference Pipeline

```
1. Load Base Model (4-bit quantized)
   â†“
2. Load LoRA Adapters (from checkpoint)
   â†“
3. Merge Adapters (optional, for faster inference)
   â†“
4. Process Input Image
   â†“
5. Generate Output (LaTeX/Text)
   - Tree-CoT reasoning
   - Error detection & fixing
   - Symbol counting consistency
   â†“
6. Post-processing & Evaluation
```

### 2.10. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

Äá»ƒ lÃ m rÃµ Æ°u Ä‘iá»ƒm cá»§a Uni-MuMER, chÃºng ta so sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªu biá»ƒu trong lÄ©nh vá»±c HMER:

**Báº£ng 2.1. So sÃ¡nh Uni-MuMER vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c**

| PhÆ°Æ¡ng phÃ¡p | Kiáº¿n trÃºc | Multi-task | Quantization | VRAM Training | Hiá»‡u suáº¥t | Kháº£ nÄƒng tá»•ng quÃ¡t |
|------------|-----------|------------|--------------|---------------|-----------|-------------------|
| **Uni-MuMER** | **VLM (Qwen2.5-VL)** | **CÃ³ (3 tasks)** | **QLoRA (4-bit)** | **20-30GB** | **SOTA** | **Cao** |
| TAMER | Transformer chuyÃªn biá»‡t | KhÃ´ng | KhÃ´ng | 60-80GB | Tá»‘t | Tháº¥p |
| CoMER | CNN + Transformer | KhÃ´ng | KhÃ´ng | 50-70GB | Tá»‘t | Tháº¥p |
| Full Fine-tuning | VLM | KhÃ´ng | KhÃ´ng | 60-80GB | Tá»‘t | Cao |
| LoRA only | VLM | KhÃ´ng | KhÃ´ng | 40-50GB | Tá»‘t | Cao |

**PhÃ¢n tÃ­ch so sÃ¡nh:**

1. **Vá» kiáº¿n trÃºc**: Uni-MuMER sá»­ dá»¥ng VLM pre-trained (Qwen2.5-VL-3B) thay vÃ¬ xÃ¢y dá»±ng tá»« Ä‘áº§u, cho phÃ©p táº­n dá»¥ng kiáº¿n thá»©c Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« dá»¯ liá»‡u Ä‘a dáº¡ng.

2. **Vá» multi-task learning**: Uni-MuMER lÃ  phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn tÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£ (Tree-CoT, EDL, SC) trong má»™t quÃ¡ trÃ¬nh training thá»‘ng nháº¥t, trong khi cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c chá»‰ táº­p trung vÃ o tÃ¡c vá»¥ nháº­n dáº¡ng chÃ­nh.

3. **Vá» quantization**: Uni-MuMER sá»­ dá»¥ng QLoRA vá»›i 4-bit quantization, giáº£m yÃªu cáº§u VRAM xuá»‘ng 50-70% so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ´ng sá»­ dá»¥ng quantization.

4. **Vá» hiá»‡u suáº¥t**: Uni-MuMER Ä‘áº¡t hiá»‡u suáº¥t state-of-the-art, vÆ°á»£t SSAN 16.31% vÃ  Gemini2.5-flash 24.42% trong thiáº¿t láº­p zero-shot.

5. **Vá» kháº£ nÄƒng tá»•ng quÃ¡t**: Do sá»­ dá»¥ng VLM pre-trained, Uni-MuMER cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n cÃ¡c mÃ´ hÃ¬nh chuyÃªn biá»‡t, cÃ³ thá»ƒ Ã¡p dá»¥ng cho cÃ¡c tÃ¡c vá»¥ thá»‹ giÃ¡c khÃ¡c.

### 2.11. Äiá»ƒm máº¡nh vÃ  Ä‘Ã³ng gÃ³p cá»§a PhÆ°Æ¡ng phÃ¡p Uni-MuMER

**Äiá»ƒm máº¡nh chÃ­nh:**

1. **Táº­n dá»¥ng kiáº¿n thá»©c pre-trained**: Sá»­ dá»¥ng Qwen2.5-VL-3B nhÆ° base model, táº­n dá»¥ng kiáº¿n thá»©c Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« hÃ ng tá»· dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng tiá»‡n, khÃ´ng cáº§n training tá»« Ä‘áº§u.

2. **Hiá»‡u quáº£ tÃ i nguyÃªn**: Sá»­ dá»¥ng QLoRA giáº£m 50-70% VRAM usage so vá»›i full fine-tuning, cho phÃ©p training trÃªn GPU consumer-grade (RTX 3090, A6000) thay vÃ¬ yÃªu cáº§u GPU cao cáº¥p (A100, H100).

3. **Multi-task learning thá»‘ng nháº¥t**: TÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£ trong má»™t quÃ¡ trÃ¬nh training, cho phÃ©p model há»c Ä‘Æ°á»£c nhiá»u khÃ­a cáº¡nh cá»§a bÃ i toÃ¡n Ä‘á»“ng thá»i, cáº£i thiá»‡n hiá»‡u suáº¥t tá»•ng thá»ƒ.

4. **Data-driven approach**: CÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c thiáº¿t káº¿ dá»±a trÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u thá»±c táº¿, Ä‘áº£m báº£o tÃ­nh thá»±c tiá»…n vÃ  hiá»‡u quáº£.

5. **State-of-the-art performance**: Äáº¡t hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn CROHME vÃ  HME100K, vÆ°á»£t cÃ¡c phÆ°Æ¡ng phÃ¡p chuyÃªn biá»‡t vÃ  VLM hÃ ng Ä‘áº§u.

6. **Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a**: Do sá»­ dá»¥ng VLM pre-trained, model cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t, cÃ³ thá»ƒ Ã¡p dá»¥ng cho cÃ¡c tÃ¡c vá»¥ thá»‹ giÃ¡c khÃ¡c ngoÃ i HMER.

**ÄÃ³ng gÃ³p nghiÃªn cá»©u:**

1. **PhÆ°Æ¡ng phÃ¡p má»›i**: Láº§n Ä‘áº§u tiÃªn Ã¡p dá»¥ng QLoRA + Multi-task Learning cho bÃ i toÃ¡n HMER, má»Ÿ ra hÆ°á»›ng nghiÃªn cá»©u má»›i vá» parameter-efficient fine-tuning trong lÄ©nh vá»±c nÃ y.

2. **TÃ­ch há»£p ba tÃ¡c vá»¥ bá»• trá»£**: Äá» xuáº¥t vÃ  tÃ­ch há»£p thÃ nh cÃ´ng ba tÃ¡c vá»¥ (Tree-CoT, EDL, SC) trong má»™t quÃ¡ trÃ¬nh training thá»‘ng nháº¥t, chá»©ng minh hiá»‡u quáº£ cá»§a multi-task learning trong HMER.

3. **Giáº£m yÃªu cáº§u tÃ i nguyÃªn**: Chá»©ng minh ráº±ng cÃ³ thá»ƒ Ä‘áº¡t hiá»‡u suáº¥t cao vá»›i tÃ i nguyÃªn háº¡n cháº¿, má»Ÿ ra kháº£ nÄƒng nghiÃªn cá»©u vÃ  triá»ƒn khai rá»™ng rÃ£i hÆ¡n.

4. **Benchmark má»›i**: Thiáº¿t láº­p benchmark má»›i cho bÃ i toÃ¡n HMER, vÆ°á»£t cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã³ Ä‘Ã¡ng ká»ƒ.

---

## 3. CÃC Ká»¸ THUáº¬T TINH CHá»ˆNH ÄÃƒ ÃP Dá»¤NG

### 3.1. QLoRA (Quantized Low-Rank Adaptation)

#### 3.1.1. KhÃ¡i niá»‡m

QLoRA lÃ  sá»± káº¿t há»£p giá»¯a **LoRA (Low-Rank Adaptation)** vÃ  **4-bit Quantization**, cho phÃ©p fine-tuning mÃ´ hÃ¬nh lá»›n vá»›i tÃ i nguyÃªn háº¡n cháº¿.

#### 3.1.2. CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng

**LoRA (Low-Rank Adaptation):**
- Thay vÃ¬ cáº­p nháº­t toÃ n bá»™ ma tráº­n trá»ng sá»‘ W (kÃ­ch thÆ°á»›c dÃ—d), LoRA phÃ¢n tÃ­ch W thÃ nh tÃ­ch cá»§a hai ma tráº­n háº¡ng tháº¥p:
  ```
  W' = W + Î”W = W + BA
  ```
  Trong Ä‘Ã³:
  - B: ma tráº­n kÃ­ch thÆ°á»›c dÃ—r (rank r)
  - A: ma tráº­n kÃ­ch thÆ°á»›c rÃ—d
  - r << d (rank nhá» hÆ¡n nhiá»u so vá»›i chiá»u gá»‘c)

**4-bit Quantization:**
- NÃ©n trá»ng sá»‘ tá»« 32-bit (FP32) hoáº·c 16-bit (FP16/BF16) xuá»‘ng 4-bit
- Sá»­ dá»¥ng **NF4 (NormalFloat4)** quantization scheme
- Giáº£m kÃ­ch thÆ°á»›c model tá»« ~3GB xuá»‘ng ~1.5GB

**QLoRA = LoRA + 4-bit Quantization:**
- Base model Ä‘Æ°á»£c quantize xuá»‘ng 4-bit vÃ  Ä‘Ã³ng bÄƒng (frozen)
- Chá»‰ train cÃ¡c LoRA adapters (ma tráº­n B vÃ  A) á»Ÿ full precision
- Káº¿t há»£p cáº£ hai ká»¹ thuáº­t Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ i nguyÃªn

#### 3.1.3. Cáº¥u hÃ¬nh trong dá»± Ã¡n

```yaml
# Tá»« file train/Uni-MuMER-train.yaml

# QLoRA configuration
quantization_bit: 4              # 4-bit quantization
quantization_type: nf4            # NormalFloat4 quantization
finetuning_type: lora             # Sá»­ dá»¥ng LoRA

# LoRA parameters
lora_target: all                  # Ãp dá»¥ng LoRA cho táº¥t cáº£ linear layers
lora_rank: 64                     # Rank cá»§a ma tráº­n phÃ¢n tÃ­ch (r=64)
lora_alpha: 16                    # Scaling factor (alpha=16)
lora_dropout: 0.05                # Dropout rate cho LoRA layers
```

**Giáº£i thÃ­ch tham sá»‘:**
- **lora_rank (r=64)**: Sá»‘ chiá»u cá»§a ma tráº­n háº¡ng tháº¥p. Rank cÃ ng cao, kháº£ nÄƒng biá»ƒu diá»…n cÃ ng tá»‘t nhÆ°ng tá»‘n nhiá»u tham sá»‘ hÆ¡n.
- **lora_alpha (Î±=16)**: Há»‡ sá»‘ scaling Ä‘á»ƒ Ä‘iá»u chá»‰nh áº£nh hÆ°á»Ÿng cá»§a LoRA adapters. Tá»· lá»‡ Î±/r = 16/64 = 0.25 lÃ  tá»· lá»‡ scaling.
- **lora_dropout (0.05)**: Tá»· lá»‡ dropout Ä‘á»ƒ trÃ¡nh overfitting.

#### 3.1.4. Lá»£i Ã­ch

**Tiáº¿t kiá»‡m bá»™ nhá»›:**
- **Training VRAM**: Giáº£m tá»« ~60-80GB xuá»‘ng ~20-30GB (giáº£m 50-70%)
- **Inference VRAM**: Giáº£m tá»« ~6GB xuá»‘ng ~2-3GB (giáº£m 50%)
- **Model size**: Giáº£m tá»« ~3GB xuá»‘ng ~1.5GB (giáº£m 50%)

**Tiáº¿t kiá»‡m tham sá»‘ trainable:**
- Thay vÃ¬ train 3 tá»· tham sá»‘, chá»‰ train ~10-20 triá»‡u tham sá»‘ (LoRA adapters)
- Giáº£m sá»‘ lÆ°á»£ng tham sá»‘ trainable xuá»‘ng ~0.3-0.7% so vá»›i full fine-tuning

**Tá»‘c Ä‘á»™ training:**
- Nhanh hÆ¡n do chá»‰ cáº­p nháº­t má»™t pháº§n nhá» tham sá»‘
- Gradient computation Ä‘Æ¡n giáº£n hÆ¡n

**Cháº¥t lÆ°á»£ng:**
- Giá»¯ Ä‘Æ°á»£c ~95-99% hiá»‡u suáº¥t so vá»›i full fine-tuning
- PhÃ¹ há»£p cho cÃ¡c tÃ¡c vá»¥ chuyÃªn biá»‡t nhÆ° HMER

---

### 3.2. 4-bit Quantization vá»›i NF4

#### 3.2.1. KhÃ¡i niá»‡m

**Quantization** lÃ  quÃ¡ trÃ¬nh giáº£m Ä‘á»™ chÃ­nh xÃ¡c cá»§a sá»‘ Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n.

#### 3.2.2. NormalFloat4 (NF4) Quantization

**Äáº·c Ä‘iá»ƒm:**
- NF4 lÃ  má»™t quantization scheme Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho cÃ¡c phÃ¢n phá»‘i trá»ng sá»‘ cá»§a neural networks
- Tá»‘i Æ°u hÃ³a cho phÃ¢n phá»‘i chuáº©n (normal distribution) cá»§a trá»ng sá»‘
- Sá»­ dá»¥ng 4-bit Ä‘á»ƒ biá»ƒu diá»…n má»—i trá»ng sá»‘ (16 giÃ¡ trá»‹ cÃ³ thá»ƒ)

**CÆ¡ cháº¿:**
1. PhÃ¢n tÃ­ch phÃ¢n phá»‘i trá»ng sá»‘ cá»§a model
2. Chá»n 16 giÃ¡ trá»‹ quantization levels tá»‘i Æ°u dá»±a trÃªn phÃ¢n phá»‘i
3. Map má»—i trá»ng sá»‘ gá»‘c Ä‘áº¿n giÃ¡ trá»‹ quantization gáº§n nháº¥t

#### 3.2.3. Cáº¥u hÃ¬nh BitsAndBytes

```python
# Cáº¥u hÃ¬nh quantization trong inference
BitsAndBytesConfig(
    load_in_4bit=True,                    # KÃ­ch hoáº¡t 4-bit quantization
    bnb_4bit_use_double_quant=True,       # Double quantization Ä‘á»ƒ giáº£m thÃªm memory
    bnb_4bit_quant_type="nf4",            # Sá»­ dá»¥ng NF4 quantization
    bnb_4bit_compute_dtype=torch.bfloat16 # Compute dtype cho operations
)
```

**Double Quantization:**
- Quantize cáº£ quantization constants (constants dÃ¹ng Ä‘á»ƒ dequantize)
- Giáº£m thÃªm ~0.4 bits per parameter
- Tá»•ng cá»™ng: ~3.5-3.6 bits per parameter thay vÃ¬ 4 bits

#### 3.2.4. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p quantization khÃ¡c

| PhÆ°Æ¡ng phÃ¡p | Bits | Äá»™ chÃ­nh xÃ¡c | Tá»‘c Ä‘á»™ | Memory |
|------------|------|--------------|--------|--------|
| FP32 (Full) | 32 | 100% | Cháº­m | Cao |
| FP16/BF16 | 16 | ~99% | Trung bÃ¬nh | Trung bÃ¬nh |
| INT8 | 8 | ~95% | Nhanh | Tháº¥p |
| **NF4 (QLoRA)** | **4** | **~90-95%** | **Ráº¥t nhanh** | **Ráº¥t tháº¥p** |

---

### 3.3. Gradient Accumulation

#### 3.3.1. Váº¥n Ä‘á»

Vá»›i quantization, batch size pháº£i giáº£m xuá»‘ng do overhead cá»§a quantization operations:
- Batch size gá»‘c: 4 samples/batch
- Batch size vá»›i quantization: 2 samples/batch (giáº£m 50%)

#### 3.3.2. Giáº£i phÃ¡p: Gradient Accumulation

**CÆ¡ cháº¿:**
- Thay vÃ¬ cáº­p nháº­t weights sau má»—i batch nhá», tÃ­ch lÅ©y gradients qua nhiá»u batches
- Chá»‰ cáº­p nháº­t weights sau khi Ä‘Ã£ tÃ­ch lÅ©y Ä‘á»§ gradients

**CÃ´ng thá»©c:**
```
Effective Batch Size = per_device_train_batch_size Ã— gradient_accumulation_steps Ã— num_gpus
```

**Cáº¥u hÃ¬nh trong dá»± Ã¡n:**
```yaml
per_device_train_batch_size: 2        # Giáº£m tá»« 4 xuá»‘ng 2
gradient_accumulation_steps: 64       # TÄƒng tá»« 1 lÃªn 64
# Effective batch size = 2 Ã— 64 = 128 (giá»¯ nguyÃªn hoáº·c tÄƒng so vá»›i ban Ä‘áº§u)
```

#### 3.3.3. Lá»£i Ã­ch

- **Duy trÃ¬ effective batch size**: Giá»¯ Ä‘Æ°á»£c batch size lá»›n Ä‘á»ƒ training á»•n Ä‘á»‹nh
- **Tiáº¿t kiá»‡m VRAM**: KhÃ´ng cáº§n tÄƒng batch size thá»±c táº¿
- **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c**: Batch size lá»›n hÆ¡n thÆ°á»ng cho gradient Æ°á»›c lÆ°á»£ng tá»‘t hÆ¡n

---

### 3.4. BFloat16 (BF16) Training

#### 3.4.1. KhÃ¡i niá»‡m

**BFloat16** lÃ  Ä‘á»‹nh dáº¡ng sá»‘ dáº¥u cháº¥m Ä‘á»™ng 16-bit Ä‘Æ°á»£c thiáº¿t káº¿ bá»Ÿi Google Brain, tÆ°Æ¡ng thÃ­ch vá»›i FP32 vá» dynamic range.

#### 3.4.2. Äáº·c Ä‘iá»ƒm

- **Dynamic range**: Giá»‘ng FP32 (8 bits exponent)
- **Precision**: Tháº¥p hÆ¡n FP32 (7 bits mantissa thay vÃ¬ 23 bits)
- **Tá»‘c Ä‘á»™**: Nhanh hÆ¡n FP32 trÃªn GPU hiá»‡n Ä‘áº¡i
- **á»”n Ä‘á»‹nh**: Ãt bá»‹ overflow/underflow hÆ¡n FP16

#### 3.4.3. Cáº¥u hÃ¬nh

```yaml
bf16: true  # Sá»­ dá»¥ng BFloat16 cho training
```

**Lá»£i Ã­ch:**
- Giáº£m memory usage so vá»›i FP32
- TÄƒng tá»‘c Ä‘á»™ training
- Giá»¯ Ä‘Æ°á»£c dynamic range, trÃ¡nh gradient vanishing/exploding

---

### 3.5. Learning Rate Scheduling

#### 3.5.1. Cosine Learning Rate Schedule

**CÆ¡ cháº¿:**
- Learning rate giáº£m dáº§n theo hÃ m cosine tá»« giÃ¡ trá»‹ ban Ä‘áº§u xuá»‘ng 0
- Táº¡o Ä‘Æ°á»ng cong mÆ°á»£t mÃ , giÃºp model há»™i tá»¥ tá»‘t hÆ¡n

**CÃ´ng thá»©c:**
```
lr(t) = lr_min + (lr_max - lr_min) Ã— (1 + cos(Ï€ Ã— t / T)) / 2
```

#### 3.5.2. Warmup

**Má»¥c Ä‘Ã­ch:**
- TrÃ¡nh learning rate quÃ¡ cao á»Ÿ Ä‘áº§u training
- GiÃºp model á»•n Ä‘á»‹nh trong nhá»¯ng bÆ°á»›c Ä‘áº§u

**Cáº¥u hÃ¬nh:**
```yaml
learning_rate: 1.0e-4        # Learning rate ban Ä‘áº§u
lr_scheduler_type: cosine     # Cosine schedule
warmup_ratio: 0.1             # 10% sá»‘ steps Ä‘áº§u dÃ¹ng warmup
```

**Giáº£i thÃ­ch:**
- Learning rate cao hÆ¡n má»™t chÃºt (1e-4) so vá»›i full fine-tuning (thÆ°á»ng 5e-5) Ä‘á»ƒ bÃ¹ cho viá»‡c chá»‰ train adapters
- Warmup 10% giÃºp model thÃ­ch á»©ng dáº§n vá»›i learning rate

---

### 3.6. Multi-Task Learning (Chi tiáº¿t bá»• sung)

#### 3.6.1. CÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c tÃ­ch há»£p (TÃ³m táº¯t)

Dá»± Ã¡n tÃ­ch há»£p **3 tÃ¡c vá»¥ chuyÃªn biá»‡t** Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t nháº­n dáº¡ng biá»ƒu thá»©c toÃ¡n há»c. Chi tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c mÃ´ táº£ trong pháº§n 2.3 (PHÆ¯Æ NG PHÃP Äá»€ XUáº¤T).

1. **Tree-Aware Chain-of-Thought (Tree-CoT)**: Há»c láº­p luáº­n khÃ´ng gian cÃ³ cáº¥u trÃºc
2. **Error-Driven Learning (EDL)**: Giáº£m nháº§m láº«n giá»¯a cÃ¡c kÃ½ tá»± trá»±c quan tÆ°Æ¡ng tá»±
3. **Symbol Counting (SC)**: Cáº£i thiá»‡n tÃ­nh nháº¥t quÃ¡n trong nháº­n dáº¡ng cÃ¡c biá»ƒu thá»©c dÃ i

#### 3.6.2. Dataset Ä‘Æ°á»£c sá»­ dá»¥ng

```yaml
dataset: 
  - parquet_crohme_train              # Dataset chÃ­nh CROHME
  - parquet_crohme_train_can          # Tree-CoT variant
  - parquet_crohme_train_tree          # Tree structure learning
  - parquet_crohme_train_error_find    # Error finding (EDL)
  - parquet_crohme_train_error_fix    # Error fixing (EDL)
  - parquet_hme100k_train             # HME100K dataset
```

---

## 4. SO SÃNH MÃ” HÃŒNH Gá»C VÃ€ TINH CHá»ˆNH

### 3.1. Báº£ng so sÃ¡nh tá»•ng quan

| TiÃªu chÃ­ | MÃ´ hÃ¬nh gá»‘c | MÃ´ hÃ¬nh tinh chá»‰nh (QLoRA) | Cáº£i thiá»‡n |
|----------|-------------|---------------------------|-----------|
| **VRAM Training** | ~60-80GB | ~20-30GB | **Giáº£m 50-70%** |
| **VRAM Inference** | ~6GB | ~2-3GB | **Giáº£m 50%** |
| **Model Size** | ~3GB | ~1.5GB | **Giáº£m 50%** |
| **Tham sá»‘ Trainable** | 3B (100%) | ~10-20M (0.3-0.7%) | **Giáº£m 99%+** |
| **Batch Size** | 4 | 2 (effective 128) | TÆ°Æ¡ng Ä‘Æ°Æ¡ng |
| **Tá»‘c Ä‘á»™ Training** | Cháº­m | Nhanh hÆ¡n 2-3x | **TÄƒng 200-300%** |
| **Äá»™ chÃ­nh xÃ¡c** | 100% (baseline) | ~95-99% | Giáº£m nháº¹ 1-5% |
| **YÃªu cáº§u GPU** | A100/H100 (80GB+) | RTX 3090/A6000 (24GB+) | **Giáº£m Ä‘Ã¡ng ká»ƒ** |

### 3.2. So sÃ¡nh chi tiáº¿t tá»«ng thÃ nh pháº§n

#### 3.2.1. Memory Usage

**MÃ´ hÃ¬nh gá»‘c (Full Fine-tuning):**
```
Base Model (FP16):          ~6GB
Optimizer States (AdamW):   ~12GB (2Ã— model size)
Gradients:                  ~6GB
Activations:                ~40-60GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tá»•ng cá»™ng:                  ~60-80GB
```

**MÃ´ hÃ¬nh tinh chá»‰nh (QLoRA):**
```
Base Model (4-bit):         ~1.5GB
LoRA Adapters (FP16):       ~0.1GB
Optimizer States:           ~0.2GB (chá»‰ cho adapters)
Gradients:                  ~0.1GB (chá»‰ cho adapters)
Activations:                ~18-28GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tá»•ng cá»™ng:                  ~20-30GB
```

**Tiáº¿t kiá»‡m:** ~40-50GB VRAM (62.5-70% reduction)

#### 3.2.2. Training Time

**MÃ´ hÃ¬nh gá»‘c:**
- Forward pass: Cáº­p nháº­t 3B tham sá»‘
- Backward pass: TÃ­nh gradient cho 3B tham sá»‘
- Update: Cáº­p nháº­t 3B tham sá»‘

**MÃ´ hÃ¬nh tinh chá»‰nh:**
- Forward pass: Chá»‰ tÃ­nh toÃ¡n vá»›i 4-bit weights (nhanh hÆ¡n)
- Backward pass: Chá»‰ tÃ­nh gradient cho ~20M tham sá»‘ LoRA
- Update: Chá»‰ cáº­p nháº­t ~20M tham sá»‘

**Tá»‘c Ä‘á»™:** Nhanh hÆ¡n 2-3 láº§n

#### 3.2.3. Model Quality

**Äá»™ chÃ­nh xÃ¡c trÃªn CROHME:**
- MÃ´ hÃ¬nh gá»‘c (zero-shot): Baseline
- MÃ´ hÃ¬nh tinh chá»‰nh: **VÆ°á»£t SSAN 16.31%**, vÆ°á»£t Gemini2.5-flash 24.42%

**Káº¿t luáº­n:** Máº·c dÃ¹ sá»­ dá»¥ng quantization, model váº«n Ä‘áº¡t hiá»‡u suáº¥t state-of-the-art nhá»:
1. Fine-tuning chuyÃªn biá»‡t cho tÃ¡c vá»¥ HMER
2. Multi-task learning vá»›i Tree-CoT, EDL, SC
3. LoRA adapters Ä‘Æ°á»£c train á»Ÿ full precision

---

## 5. CHI TIáº¾T Ká»¸ THUáº¬T TRIá»‚N KHAI

### 4.1. Training Pipeline

#### 4.1.1. Quy trÃ¬nh training

```
1. Load Base Model (Qwen2.5-VL-3B)
   â†“
2. Apply 4-bit Quantization (NF4)
   â†“
3. Freeze Base Model Weights
   â†“
4. Initialize LoRA Adapters
   - Target: All linear layers
   - Rank: 64
   - Alpha: 16
   â†“
5. Training Loop
   - Forward: Base model (4-bit) + LoRA adapters (FP16)
   - Backward: Compute gradients cho LoRA adapters only
   - Update: Chá»‰ cáº­p nháº­t LoRA weights
   â†“
6. Save Checkpoints
   - Chá»‰ lÆ°u LoRA adapters (~100MB)
   - KhÃ´ng lÆ°u base model
```

#### 4.1.2. Code implementation

**Cáº¥u hÃ¬nh training (YAML):**
```yaml
# train/Uni-MuMER-train.yaml
model_name_or_path: Qwen/Qwen2.5-VL-3B-Instruct
finetuning_type: lora
quantization_bit: 4
quantization_type: nf4
lora_rank: 64
lora_alpha: 16
lora_dropout: 0.05
per_device_train_batch_size: 2
gradient_accumulation_steps: 64
learning_rate: 1.0e-4
bf16: true
```

**Training command:**
```bash
llamafactory-cli train train/Uni-MuMER-train.yaml
```

### 4.2. Inference Pipeline

#### 4.2.1. Merge LoRA Adapters

Sau training, cáº§n merge LoRA adapters vÃ o base model Ä‘á»ƒ inference:

```python
# scripts/merge_checkpoint.py
base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    base_model_dir,
    torch_dtype=torch.bfloat16
)

adapter_model = PeftModel.from_pretrained(base_model, checkpoint_dir)
merged_model = adapter_model.merge_and_unload()
merged_model.save_pretrained(output_dir)
```

**Lá»£i Ã­ch:**
- Táº¡o má»™t model thá»‘ng nháº¥t, khÃ´ng cáº§n load riÃªng adapters
- TÄƒng tá»‘c Ä‘á»™ inference
- Dá»… dÃ ng deploy

#### 4.2.2. Inference vá»›i vLLM

**Cáº¥u hÃ¬nh:**
```python
# scripts/vllm_infer.py
llm = LLM(
    model=model_name,
    quantization="bitsandbytes",  # 4-bit quantization
    dtype="half",
    enforce_eager=True,            # Tiáº¿t kiá»‡m VRAM
    gpu_memory_utilization=0.95,
    max_model_len=2048
)
```

**Lá»£i Ã­ch cá»§a vLLM:**
- Dynamic batching: Tá»± Ä‘á»™ng batch cÃ¡c requests
- PagedAttention: Quáº£n lÃ½ memory hiá»‡u quáº£
- Continuous batching: Xá»­ lÃ½ requests khÃ´ng Ä‘á»“ng bá»™

---

## 6. Káº¾T QUáº¢ VÃ€ ÄÃNH GIÃ

### 5.1. Hiá»‡u suáº¥t trÃªn cÃ¡c dataset

#### 5.1.1. Káº¿t quáº£ chÃ­nh tá»« Paper Uni-MuMER

Theo [paper chÃ­nh thá»©c](https://arxiv.org/abs/2505.23566), Uni-MuMER Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c káº¿t quáº£ sau:

**CROHME Dataset:**
- VÆ°á»£t qua mÃ´ hÃ¬nh chuyÃªn biá»‡t nháº¹ tá»‘t nháº¥t **SSAN 16.31%**
- VÆ°á»£t qua VLM hÃ ng Ä‘áº§u **Gemini2.5-flash 24.42%** trong thiáº¿t láº­p zero-shot
- Äáº¡t hiá»‡u suáº¥t state-of-the-art má»›i trÃªn cáº£ CROHME vÃ  HME100K

**HME100K Dataset:**
- Cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p baseline
- Thá»ƒ hiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t

#### 5.1.2. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

| PhÆ°Æ¡ng phÃ¡p | Hiá»‡u suáº¥t | VRAM | Training Time | Ghi chÃº |
|------------|-----------|------|---------------|---------|
| Full Fine-tuning | Baseline | 60-80GB | Baseline | YÃªu cáº§u GPU cao cáº¥p |
| **Uni-MuMER (QLoRA)** | **SOTA** | **20-30GB** | **2-3x nhanh hÆ¡n** | **VÆ°á»£t SSAN 16.31%, Gemini2.5-flash 24.42%** |
| LoRA (khÃ´ng quantize) | TÆ°Æ¡ng Ä‘Æ°Æ¡ng | 40-50GB | 1.5x nhanh hÆ¡n | KhÃ´ng sá»­ dá»¥ng quantization |
| SSAN | Baseline | - | - | MÃ´ hÃ¬nh chuyÃªn biá»‡t nháº¹ tá»‘t nháº¥t trÆ°á»›c Ä‘Ã³ |
| Gemini2.5-flash | Baseline | - | - | VLM hÃ ng Ä‘áº§u trÆ°á»›c Ä‘Ã³ |

### 5.2. PhÃ¢n tÃ­ch tÃ i nguyÃªn

#### 5.2.1. Memory Breakdown

**Training:**
- Base Model (4-bit): 1.5GB
- LoRA Adapters: 0.1GB
- Optimizer: 0.2GB
- Activations: 18-28GB
- **Tá»•ng: 20-30GB**

**Inference:**
- Model (4-bit): 1.5GB
- KV Cache: 0.5-1GB
- Activations: 0.5-1GB
- **Tá»•ng: 2-3GB**

#### 5.2.2. Training Speed

- **Steps per second**: TÄƒng 2-3x so vá»›i full fine-tuning
- **Time to convergence**: Giáº£m 50-60%
- **Total training time**: Giáº£m Ä‘Ã¡ng ká»ƒ

### 5.3. Trade-offs

#### 5.3.1. Æ¯u Ä‘iá»ƒm

âœ… **Tiáº¿t kiá»‡m tÃ i nguyÃªn:**
- Giáº£m 50-70% VRAM
- Giáº£m 99%+ tham sá»‘ trainable
- CÃ³ thá»ƒ train trÃªn GPU consumer-grade

âœ… **Tá»‘c Ä‘á»™:**
- Training nhanh hÆ¡n 2-3x
- Inference nhanh hÆ¡n nhá» model nhá» hÆ¡n

âœ… **Linh hoáº¡t:**
- Dá»… dÃ ng thá»­ nghiá»‡m vá»›i nhiá»u cáº¥u hÃ¬nh LoRA
- CÃ³ thá»ƒ train nhiá»u adapters cho nhiá»u tÃ¡c vá»¥

âœ… **Cháº¥t lÆ°á»£ng:**
- Giá»¯ Ä‘Æ°á»£c 95-99% hiá»‡u suáº¥t
- Äáº¡t state-of-the-art trÃªn CROHME

#### 5.3.2. NhÆ°á»£c Ä‘iá»ƒm

âŒ **Äá»™ chÃ­nh xÃ¡c:**
- Giáº£m nháº¹ 1-5% so vá»›i full fine-tuning
- Quantization cÃ³ thá»ƒ gÃ¢y máº¥t mÃ¡t thÃ´ng tin

âŒ **Phá»©c táº¡p:**
- Cáº§n merge adapters sau training
- Cáº¥u hÃ¬nh phá»©c táº¡p hÆ¡n

âŒ **Háº¡n cháº¿:**
- KhÃ´ng thá»ƒ thay Ä‘á»•i kiáº¿n trÃºc model
- LoRA rank cáº§n Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cáº©n tháº­n

---

## 7. Káº¾T LUáº¬N VÃ€ HÆ¯á»šNG PHÃT TRIá»‚N

### 6.1. Káº¿t luáº­n

Dá»± Ã¡n **Uni-MuMER** Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c tinh chá»‰nh mÃ´ hÃ¬nh Qwen2.5-VL-3B báº±ng cÃ¡c ká»¹ thuáº­t:

1. **QLoRA**: Káº¿t há»£p LoRA vÃ  4-bit quantization Ä‘á»ƒ giáº£m tÃ i nguyÃªn
2. **NF4 Quantization**: Sá»­ dá»¥ng NormalFloat4 Ä‘á»ƒ tá»‘i Æ°u hÃ³a quantization
3. **Gradient Accumulation**: Duy trÃ¬ effective batch size lá»›n
4. **BFloat16 Training**: TÄƒng tá»‘c Ä‘á»™ vÃ  giáº£m memory
5. **Multi-task Learning**: TÃ­ch há»£p Tree-CoT, EDL, SC Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t

**Káº¿t quáº£ chÃ­nh:**
- **Hiá»‡u suáº¥t**: VÆ°á»£t SSAN 16.31% vÃ  Gemini2.5-flash 24.42% trong zero-shot setting
- **TÃ i nguyÃªn**: Giáº£m 50-70% VRAM usage (tá»« 60-80GB xuá»‘ng 20-30GB)
- **Tham sá»‘**: Giáº£m 99%+ tham sá»‘ trainable (chá»‰ train LoRA adapters)
- **Tá»‘c Ä‘á»™**: TÄƒng tá»‘c Ä‘á»™ training 2-3x so vá»›i full fine-tuning
- **Äá»™ chÃ­nh xÃ¡c**: Äáº¡t hiá»‡u suáº¥t state-of-the-art trÃªn CROHME vÃ  HME100K
- **Kháº£ nÄƒng triá»ƒn khai**: CÃ³ thá»ƒ train trÃªn GPU consumer-grade (RTX 3090, A6000)

**CÃ´ng nháº­n:**
- ÄÆ°á»£c cháº¥p nháº­n táº¡i **NeurIPS 2025 vá»›i danh hiá»‡u Spotlight** (688/21575 submissions)
- Paper: [arXiv:2505.23566](https://arxiv.org/abs/2505.23566)

### 6.2. HÆ°á»›ng phÃ¡t triá»ƒn

#### 6.2.1. Tá»‘i Æ°u hÃ³a thÃªm

1. **LoRA++**: Cáº£i thiá»‡n LoRA vá»›i rank factorization tá»‘t hÆ¡n
2. **QLoRA variants**: Thá»­ nghiá»‡m vá»›i 3-bit, 2-bit quantization
3. **AdaLoRA**: Adaptive LoRA rank cho tá»«ng layer
4. **DoRA**: Weight-Decomposed Low-Rank Adaptation

#### 6.2.2. Má»Ÿ rá»™ng á»©ng dá»¥ng

1. **Multi-domain**: Ãp dá»¥ng cho cÃ¡c domain khÃ¡c (hÃ³a há»c, váº­t lÃ½, v.v.)
2. **Real-time inference**: Tá»‘i Æ°u hÃ³a cho deployment thá»i gian thá»±c
3. **Edge devices**: Quantize thÃªm Ä‘á»ƒ cháº¡y trÃªn mobile/edge devices

#### 6.2.3. NghiÃªn cá»©u sÃ¢u hÆ¡n

1. **Ablation studies**: PhÃ¢n tÃ­ch Ä‘Ã³ng gÃ³p cá»§a tá»«ng component
2. **Optimal LoRA rank**: TÃ¬m rank tá»‘i Æ°u cho tá»«ng layer
3. **Quantization-aware training**: Cáº£i thiá»‡n cháº¥t lÆ°á»£ng quantization

---

## 8. TÃ€I LIá»†U THAM KHáº¢O

### 7.1. Papers

1. **Uni-MuMER (ChÃ­nh)**: 
   - Li, Y., Jiang, J., Zhu, J., Peng, S., Wei, B., Zhou, Y., & Gao, L. (2025). 
   - "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition"
   - arXiv preprint arXiv:2505.23566
   - **NeurIPS 2025 Spotlight** (688/21575)
   - Link: https://arxiv.org/abs/2505.23566

2. **LoRA**: 
   - Hu, E. J., et al. (2021). 
   - "LoRA: Low-Rank Adaptation of Large Language Models"
   - arXiv preprint arXiv:2106.09685

3. **QLoRA**: 
   - Dettmers, T., et al. (2023). 
   - "QLoRA: Efficient Finetuning of Quantized LLMs"
   - arXiv preprint arXiv:2305.14314

4. **NF4 Quantization**: 
   - ÄÆ°á»£c giá»›i thiá»‡u trong paper QLoRA (Dettmers et al., 2023)

### 7.2. Repository vÃ  Code

1. **Uni-MuMER Official Repository**: 
   - https://github.com/BFlameSwift/Uni-MuMER
   - Repository chÃ­nh thá»©c cá»§a dá»± Ã¡n Uni-MuMER
   - Chá»©a code training, inference, vÃ  evaluation

2. **HuggingFace Datasets & Models**: 
   - https://huggingface.co/datasets/phxember/Uni-MuMER-Data
   - https://huggingface.co/collections/phxember/uni-mumer-68bfba4747e9289232f3d89e

### 7.3. Tools vÃ  Frameworks

1. **LLaMA-Factory**: https://github.com/hiyouga/LLaMA-Factory
   - Framework Ä‘Æ°á»£c sá»­ dá»¥ng cho training
   
2. **BitsAndBytes**: https://github.com/TimDettmers/bitsandbytes
   - ThÆ° viá»‡n cho 4-bit quantization
   
3. **PEFT**: https://github.com/huggingface/peft
   - Parameter-Efficient Fine-Tuning library (LoRA implementation)
   
4. **vLLM**: https://github.com/vllm-project/vllm
   - Framework tá»‘i Æ°u cho inference

### 7.4. Datasets

1. **CROHME**: Competition on Recognition of Online Handwritten Mathematical Expressions
   - Dataset tiÃªu chuáº©n cho Ä‘Ã¡nh giÃ¡ HMER
   - Bao gá»“m CROHME 2014, 2016, 2019, 2023

2. **HME100K**: Handwritten Mathematical Expression Recognition Dataset
   - Dataset lá»›n vá»›i 100K samples
   - ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a

3. **Uni-MuMER-Data**: 
   - Dataset Ä‘Æ°á»£c táº¡o bá»Ÿi nhÃ³m Uni-MuMER
   - Bao gá»“m cÃ¡c variants: Tree-CoT, EDL (error_find, error_fix), Symbol Counting
   - Link: https://huggingface.co/datasets/phxember/Uni-MuMER-Data

4. **CÃ¡c datasets khÃ¡c**:
   - Im2LaTeXv2
   - MathWriting
   - MNE (Mathematical Notation Extraction)

---

## 9. PHá»¤ Lá»¤C

### 8.1. Cáº¥u hÃ¬nh Ä‘áº§y Ä‘á»§

Xem file `train/Uni-MuMER-train.yaml` Ä‘á»ƒ biáº¿t cáº¥u hÃ¬nh Ä‘áº§y Ä‘á»§.

### 8.2. Scripts

- `scripts/merge_checkpoint.py`: Merge LoRA adapters vÃ o base model
- `scripts/vllm_infer.py`: Inference vá»›i vLLM vÃ  4-bit quantization
- `scripts/eval_metrics_calculator.py`: TÃ­nh toÃ¡n metrics Ä‘Ã¡nh giÃ¡

### 8.3. Requirements

Xem file `requirements.txt` Ä‘á»ƒ biáº¿t danh sÃ¡ch dependencies Ä‘áº§y Ä‘á»§.

---

---

## 10. THÃ”NG TIN Dá»° ÃN

**Dá»± Ã¡n gá»‘c**: Uni-MuMER  
**Repository chÃ­nh thá»©c**: https://github.com/BFlameSwift/Uni-MuMER  
**Paper**: [arXiv:2505.23566](https://arxiv.org/abs/2505.23566)  
**Conference**: NeurIPS 2025 Spotlight (688/21575 submissions)  
**TÃ¡c giáº£ paper**: Li, Yu; Jiang, Jin; Zhu, Jianhua; Peng, Shuai; Wei, Baole; Zhou, Yuxuan; Gao, Liangcai

**BÃ¡o cÃ¡o nÃ y**:  
**TÃ¡c giáº£**: [TÃªn cá»§a báº¡n]  
**NgÃ y**: [NgÃ y hiá»‡n táº¡i]  
**Äá»“ Ã¡n**: Khoa há»c MÃ¡y tÃ­nh - Nháº­n dáº¡ng Biá»ƒu thá»©c ToÃ¡n há»c Viáº¿t tay  
**Dá»±a trÃªn**: Implementation cá»§a Uni-MuMER tá»« repository chÃ­nh thá»©c

---

**LÆ°u Ã½**: BÃ¡o cÃ¡o nÃ y phÃ¢n tÃ­ch cÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng trong Uni-MuMER dá»±a trÃªn code vÃ  cáº¥u hÃ¬nh tá»« repository chÃ­nh thá»©c. Táº¥t cáº£ cÃ¡c ká»¹ thuáº­t vÃ  káº¿t quáº£ Ä‘Æ°á»£c mÃ´ táº£ Ä‘á»u dá»±a trÃªn paper vÃ  implementation chÃ­nh thá»©c cá»§a Uni-MuMER.

